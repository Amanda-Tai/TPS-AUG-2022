{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-01-09T13:39:51.676186Z","iopub.status.busy":"2023-01-09T13:39:51.675512Z","iopub.status.idle":"2023-01-09T13:39:54.277726Z","shell.execute_reply":"2023-01-09T13:39:54.276297Z","shell.execute_reply.started":"2023-01-09T13:39:51.676018Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random\n","import os\n","import csv\n","import joblib\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GroupKFold, train_test_split\n","\n","from catboost import CatBoostClassifier\n","from sklearn.linear_model import SGDClassifier, LinearRegression, LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.metrics import roc_auc_score"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:39:54.281958Z","iopub.status.busy":"2023-01-09T13:39:54.281287Z","iopub.status.idle":"2023-01-09T13:39:54.655996Z","shell.execute_reply":"2023-01-09T13:39:54.654038Z","shell.execute_reply.started":"2023-01-09T13:39:54.281919Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train.csv\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 26570 entries, 0 to 26569\n","Data columns (total 25 columns):\n"," #   Column          Non-Null Count  Dtype  \n","---  ------          --------------  -----  \n"," 0   product_code    26570 non-null  object \n"," 1   loading         26320 non-null  float64\n"," 2   attribute_0     26570 non-null  object \n"," 3   attribute_1     26570 non-null  object \n"," 4   attribute_2     26570 non-null  int64  \n"," 5   attribute_3     26570 non-null  int64  \n"," 6   measurement_0   26570 non-null  int64  \n"," 7   measurement_1   26570 non-null  int64  \n"," 8   measurement_2   26570 non-null  int64  \n"," 9   measurement_3   26189 non-null  float64\n"," 10  measurement_4   26032 non-null  float64\n"," 11  measurement_5   25894 non-null  float64\n"," 12  measurement_6   25774 non-null  float64\n"," 13  measurement_7   25633 non-null  float64\n"," 14  measurement_8   25522 non-null  float64\n"," 15  measurement_9   25343 non-null  float64\n"," 16  measurement_10  25270 non-null  float64\n"," 17  measurement_11  25102 non-null  float64\n"," 18  measurement_12  24969 non-null  float64\n"," 19  measurement_13  24796 non-null  float64\n"," 20  measurement_14  24696 non-null  float64\n"," 21  measurement_15  24561 non-null  float64\n"," 22  measurement_16  24460 non-null  float64\n"," 23  measurement_17  24286 non-null  float64\n"," 24  failure         26570 non-null  int64  \n","dtypes: float64(16), int64(6), object(3)\n","memory usage: 5.3+ MB\n"]}],"source":["TRAIN = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2022/train.csv', index_col='id')\n","TEST = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2022/test.csv', index_col='id')\n","\n","# 列出 train.csv 中的訊息，可以清楚看到在 26570 筆資料中有一些資料為空。\n","print(\"train.csv\")\n","TRAIN.info()"]},{"cell_type":"markdown","metadata":{},"source":["# 填上缺失的Data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:39:54.659529Z","iopub.status.busy":"2023-01-09T13:39:54.658192Z","iopub.status.idle":"2023-01-09T13:39:54.673568Z","shell.execute_reply":"2023-01-09T13:39:54.672340Z","shell.execute_reply.started":"2023-01-09T13:39:54.659472Z"},"trusted":true},"outputs":[],"source":["#將 train.csv 中的 failure 欄(column)刪除，並將 axis = 1 ，表示該 failure 為 column。\n","x = TRAIN.drop('failure', axis=1)\n","\n","#將 train.csv 中的 failure 欄(column)賦予給 y 。\n","y = TRAIN.failure\n","\n","#將 test.csv 複製給 test_copy 。\n","test_copy = TEST.copy()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:39:54.678105Z","iopub.status.busy":"2023-01-09T13:39:54.677258Z","iopub.status.idle":"2023-01-09T13:39:54.703846Z","shell.execute_reply":"2023-01-09T13:39:54.702212Z","shell.execute_reply.started":"2023-01-09T13:39:54.678034Z"},"trusted":true},"outputs":[],"source":["# 將 x 中 data type 為 object 的欄紀錄起來放進 cat_cols。\n","cat_cols = [cname for cname in x.columns if x[cname].dtype == 'object']\n","\n","# 將 x 中 data type 為 float64 或 int64 的欄紀錄起來放進 num_cols。\n","num_cols = [cname for cname in x.columns if x[cname].dtype in ['float64', 'int64']]\n","\n","# 將 x 中各欄(columns)有空(is null = 1)的欄紀錄起來放進 na_cols。\n","na_cols = [cname for cname in x.columns if x[cname].isnull().sum() > 0]\n","\n","# 將 x 中各欄(columns)非空(isnull = 0)的欄紀錄起來放進 none_na_cols。\n","none_na_cols = [cname for cname in x.columns if cname not in na_cols]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:39:54.706324Z","iopub.status.busy":"2023-01-09T13:39:54.705504Z","iopub.status.idle":"2023-01-09T13:39:54.715938Z","shell.execute_reply":"2023-01-09T13:39:54.714351Z","shell.execute_reply.started":"2023-01-09T13:39:54.706274Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["31639\n"]}],"source":["# 定義 random_state\n","SEED = random.randint(30000, 35000)\n","print(SEED)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:39:54.719493Z","iopub.status.busy":"2023-01-09T13:39:54.717868Z","iopub.status.idle":"2023-01-09T13:40:07.190968Z","shell.execute_reply":"2023-01-09T13:40:07.190028Z","shell.execute_reply.started":"2023-01-09T13:39:54.719429Z"},"trusted":true},"outputs":[],"source":["# 利用 Scikit-learn 中的 IterativeImputer 來補足缺失的資料\n","# max_iter：指定填充缺失值的迭代次數。\n","# skip_complete：指定是否跳過沒有缺失值的樣本。設為 True，表示會跳過沒有缺失值的樣本。。\n","# n_nearest_features：指定在填充缺失值時使用多少個相似的特徵。\n","# random_state：指定隨機數生成器的種類。\n","imputer = IterativeImputer(max_iter=50, skip_complete=True, n_nearest_features=20, random_state=SEED)\n","\n","# 利用 pd.concat 將 x, test_copy 的行(row)連起來放入 data。\n","data = pd.concat([x, test_copy], axis=0)\n","\n","# 賦值\n","# data.loc 函數選擇了所有與當前匹配的行\n","# 並將這些行的所有數值型列傳遞給了 IterativeImputer 的 fit_transform 方法\n","# 我們使用賦值運算符將估計值替換回原來的數據\n","for code in data['product_code'].unique():\n","    data.loc[data['product_code']==code, num_cols] = imputer.fit_transform(data.loc[data['product_code']==code, num_cols])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.198179Z","iopub.status.busy":"2023-01-09T13:40:07.195690Z","iopub.status.idle":"2023-01-09T13:40:07.222593Z","shell.execute_reply":"2023-01-09T13:40:07.221111Z","shell.execute_reply.started":"2023-01-09T13:40:07.198112Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 47345 entries, 0 to 47344\n","Data columns (total 24 columns):\n"," #   Column          Non-Null Count  Dtype  \n","---  ------          --------------  -----  \n"," 0   product_code    47345 non-null  object \n"," 1   loading         47345 non-null  float64\n"," 2   attribute_0     47345 non-null  object \n"," 3   attribute_1     47345 non-null  object \n"," 4   attribute_2     47345 non-null  float64\n"," 5   attribute_3     47345 non-null  float64\n"," 6   measurement_0   47345 non-null  float64\n"," 7   measurement_1   47345 non-null  float64\n"," 8   measurement_2   47345 non-null  float64\n"," 9   measurement_3   47345 non-null  float64\n"," 10  measurement_4   47345 non-null  float64\n"," 11  measurement_5   47345 non-null  float64\n"," 12  measurement_6   47345 non-null  float64\n"," 13  measurement_7   47345 non-null  float64\n"," 14  measurement_8   47345 non-null  float64\n"," 15  measurement_9   47345 non-null  float64\n"," 16  measurement_10  47345 non-null  float64\n"," 17  measurement_11  47345 non-null  float64\n"," 18  measurement_12  47345 non-null  float64\n"," 19  measurement_13  47345 non-null  float64\n"," 20  measurement_14  47345 non-null  float64\n"," 21  measurement_15  47345 non-null  float64\n"," 22  measurement_16  47345 non-null  float64\n"," 23  measurement_17  47345 non-null  float64\n","dtypes: float64(21), object(3)\n","memory usage: 9.0+ MB\n"]}],"source":["data.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 資料預處理"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.225145Z","iopub.status.busy":"2023-01-09T13:40:07.224416Z","iopub.status.idle":"2023-01-09T13:40:07.281031Z","shell.execute_reply":"2023-01-09T13:40:07.279749Z","shell.execute_reply.started":"2023-01-09T13:40:07.225074Z"},"trusted":true},"outputs":[],"source":["for col in ['attribute_0', 'attribute_1']:\n","    tempdf = pd.get_dummies(data[col], prefix=col)\n","    data = pd.merge(left=data, right=tempdf, left_index=True, right_index=True)\n","data = data.drop(['attribute_0', 'attribute_1'], axis=1)\n","\n","e = data.drop('attribute_0_material_5', axis=1, inplace=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.283670Z","iopub.status.busy":"2023-01-09T13:40:07.283002Z","iopub.status.idle":"2023-01-09T13:40:07.386362Z","shell.execute_reply":"2023-01-09T13:40:07.384365Z","shell.execute_reply.started":"2023-01-09T13:40:07.283620Z"},"trusted":true},"outputs":[],"source":["# na_cols = x 中各欄(columns)有空(is null = 1)的欄紀錄起來放進 na_cols。\n","for cname in na_cols:\n","    x[f'na_{cname}'] = np.where(x[cname].isna()==True, 1, 0)\n","    test_copy[f'na_{cname}'] = np.where(test_copy[cname].isna()==True, 1, 0)\n","na_vars = [cname for cname in x.columns if 'na' in cname]\n","\n","# 紀錄'measurement_3'及'measurement_5'中有哪些缺值\n","# 加入新的 column 'xxx' 到 data \n","data['measurement_3_na'] = data['measurement_3'].isna().astype(int)\n","data['measurement_5_na'] = data['measurement_5'].isna().astype(int)\n","\n","# Combination\n","data['attribute_2*3'] = data['attribute_2'] * data['attribute_3']\n","\n","# aggregation\n","meas_gr1_cols = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n","data['meas_gr1_avg'] = np.mean(data[meas_gr1_cols], axis=1)\n","data['meas_gr1_std'] = np.std(data[meas_gr1_cols], axis=1)\n","meas_gr2_cols = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n","data['meas_gr2_avg'] = np.mean(data[meas_gr2_cols], axis=1)\n","\n","# Ratio\n","data['meas17/meas_gr2_avg'] = data['measurement_17'] / data['meas_gr2_avg']\n","\n","x = data.iloc[:x.shape[0], :].copy()\n","test_copy = data.iloc[x.shape[0]:, :].copy()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.394054Z","iopub.status.busy":"2023-01-09T13:40:07.393101Z","iopub.status.idle":"2023-01-09T13:40:07.442163Z","shell.execute_reply":"2023-01-09T13:40:07.440585Z","shell.execute_reply.started":"2023-01-09T13:40:07.393990Z"},"trusted":true},"outputs":[],"source":["scale_feats = [col for col in x.columns if x[col].dtypes == 'float64']\n","# StandardScaler 是 scikit-learn 中的一個類，它可以對輸入數據進行標準化處理，使其分佈滿足均值為 0，方差為 1 的正態分佈。\n","scaler = StandardScaler()\n","\n","x[scale_feats] = scaler.fit_transform(x[scale_feats])\n","test_copy[scale_feats] = scaler.transform(test_copy[scale_feats])"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Selection"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.445344Z","iopub.status.busy":"2023-01-09T13:40:07.444040Z","iopub.status.idle":"2023-01-09T13:40:07.457272Z","shell.execute_reply":"2023-01-09T13:40:07.455799Z","shell.execute_reply.started":"2023-01-09T13:40:07.445255Z"},"trusted":true},"outputs":[],"source":["def FisherScore(x, y, predictors):\n","    \n","    target_var_val = y.unique()\n","    \n","    # 對每一個 predictor 算出對應的 FisherScore\n","    predictor_FisherScore = []\n","    for cname in predictors:\n","        fs = np.abs(np.mean(x.loc[y == target_var_val[0], cname]) - np.mean(x.loc[y == target_var_val[1], cname])) / \\\n","            np.sqrt(np.var(x.loc[y == target_var_val[0], cname]) + np.var(x.loc[y == target_var_val[1], cname]))\n","        predictor_FisherScore.append(fs)\n","    return predictor_FisherScore"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.461302Z","iopub.status.busy":"2023-01-09T13:40:07.459828Z","iopub.status.idle":"2023-01-09T13:40:07.629919Z","shell.execute_reply":"2023-01-09T13:40:07.628426Z","shell.execute_reply.started":"2023-01-09T13:40:07.461254Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n","  if __name__ == \"__main__\":\n"]}],"source":["# 對每一個 variables  算出對應的 FisherScore\n","fs = FisherScore(x, y, x.drop('product_code', axis=1).columns)\n","fs_df = pd.DataFrame({\"predictor\": x.drop('product_code', axis=1).columns, \"fisherscore\": fs})"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.632970Z","iopub.status.busy":"2023-01-09T13:40:07.631727Z","iopub.status.idle":"2023-01-09T13:40:07.657539Z","shell.execute_reply":"2023-01-09T13:40:07.655998Z","shell.execute_reply.started":"2023-01-09T13:40:07.632908Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>predictor</th>\n","      <th>fisherscore</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>loading</td>\n","      <td>0.217027</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>measurement_17</td>\n","      <td>0.056489</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>meas_gr2_avg</td>\n","      <td>0.056425</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>meas17/meas_gr2_avg</td>\n","      <td>0.053893</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>attribute_3</td>\n","      <td>0.033091</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>measurement_8</td>\n","      <td>0.029819</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>measurement_7</td>\n","      <td>0.029784</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>measurement_5</td>\n","      <td>0.028152</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>measurement_2</td>\n","      <td>0.027061</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>attribute_2*3</td>\n","      <td>0.026810</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             predictor  fisherscore\n","0              loading     0.217027\n","1       measurement_17     0.056489\n","2         meas_gr2_avg     0.056425\n","3  meas17/meas_gr2_avg     0.053893\n","4          attribute_3     0.033091\n","5        measurement_8     0.029819\n","6        measurement_7     0.029784\n","7        measurement_5     0.028152\n","8        measurement_2     0.027061\n","9        attribute_2*3     0.026810"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# sort 完後得出 fisherscore 高的特徵進行選取\n","fs_df = fs_df.sort_values('fisherscore', ascending=False).reset_index(drop=True)\n","fs_df.head(10)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.660427Z","iopub.status.busy":"2023-01-09T13:40:07.659114Z","iopub.status.idle":"2023-01-09T13:40:07.672773Z","shell.execute_reply":"2023-01-09T13:40:07.671201Z","shell.execute_reply.started":"2023-01-09T13:40:07.660380Z"},"trusted":true},"outputs":[],"source":["best_feats = fs_df['predictor'][:19]\n","x = x[best_feats]\n","test_copy = test_copy[best_feats]"]},{"cell_type":"markdown","metadata":{},"source":["# RUN"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.675310Z","iopub.status.busy":"2023-01-09T13:40:07.674597Z","iopub.status.idle":"2023-01-09T13:40:07.684146Z","shell.execute_reply":"2023-01-09T13:40:07.683110Z","shell.execute_reply.started":"2023-01-09T13:40:07.675249Z"},"trusted":true},"outputs":[],"source":["auc_list = []\n","test_pred_list = []\n","# importance_list = []\n","kfold = GroupKFold(n_splits=len(TRAIN.product_code.unique()))\n","model = LogisticRegression(max_iter = 500, C=0.05, penalty='l1', solver='liblinear', random_state=SEED)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.686396Z","iopub.status.busy":"2023-01-09T13:40:07.685411Z","iopub.status.idle":"2023-01-09T13:40:07.695884Z","shell.execute_reply":"2023-01-09T13:40:07.694728Z","shell.execute_reply.started":"2023-01-09T13:40:07.686344Z"},"trusted":true},"outputs":[],"source":["# model.save('/kaggle/working/my_model.h5') \n","# model = load_model('/kaggle/working/my_model.h5')\n","filename = '/kaggle/working/my_model.pkl'\n","joblib.dump(model, filename)\n","\n","filename = '/kaggle/working/my_model.pkl'\n","model = joblib.load(filename)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:07.698392Z","iopub.status.busy":"2023-01-09T13:40:07.697303Z","iopub.status.idle":"2023-01-09T13:40:11.523684Z","shell.execute_reply":"2023-01-09T13:40:11.518631Z","shell.execute_reply.started":"2023-01-09T13:40:07.698348Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0 accuracy = 0.58521\n","Fold 1 accuracy = 0.58518\n","Fold 2 accuracy = 0.59206\n","Fold 3 accuracy = 0.59820\n","Fold 4 accuracy = 0.59253\n","Average accuracy = 0.59063\n"]}],"source":["for fold, (idx_tr, idx_va) in enumerate(kfold.split(x, y, TRAIN.product_code)):\n","    X_tr = x.iloc[idx_tr]\n","    X_va = x.iloc[idx_va]\n","    y_tr = y.loc[idx_tr]\n","    y_va = y.loc[idx_va]\n","    \n","    model.fit(X_tr, y_tr)\n","    # importance_list.append(model.coef_.ravel())\n","    \n","    va_preds = model.predict_proba(X_va)[:,1]\n","    score = roc_auc_score(y_va, va_preds)\n","    print(f\"Fold {fold} accuracy = {score:.5f}\")\n","    auc_list.append(score)\n","    \n","    test_pred_list.append(model.predict_proba(test_copy)[:,1])\n","    \n","print(f'Average accuracy = {sum(auc_list) / len(auc_list):.5f}')"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T13:40:11.531600Z","iopub.status.busy":"2023-01-09T13:40:11.526669Z","iopub.status.idle":"2023-01-09T13:40:11.658347Z","shell.execute_reply":"2023-01-09T13:40:11.657024Z","shell.execute_reply.started":"2023-01-09T13:40:11.531512Z"},"trusted":true},"outputs":[],"source":["output = pd.DataFrame(columns=['id', 'failure'])\n","output['id'] = test_copy.index\n","# pread = output['failure']\n","output['failure'] = sum(test_pred_list)/len(test_pred_list)\n","output.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
